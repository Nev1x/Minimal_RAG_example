# –∑–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –≤ Qdrant

import os
import pandas as pd
from tqdm import tqdm
from dotenv import load_dotenv
from qdrant_client import QdrantClient, models
from qdrant_client.models import VectorParams, Distance

from embeddings import get_embeddings  # –º–æ–¥—É–ª—å ROSBERTa

# === –ó–∞–≥—Ä—É–∂–∞–µ–º env ===
load_dotenv()
QDRANT_URL = os.getenv("QDRANT_URL")
COLLECTION_NAME = os.getenv("COLLECTION_NAME")
DATA_PATH = os.getenv("DATA_PATH")


# --- –†–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞–Ω–∫–∏ ---
def chunk_text(question: str, answer: str) -> list[str]:
    """
    –î–ª—è –Ω–µ–±–æ–ª—å—à–æ–π –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π (–¥–æ ~1000 —Å—Ç—Ä–æ–∫) –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é —Å—Ö–µ–º—É:
    –æ–¥–∏–Ω FAQ = –æ–¥–∏–Ω —á–∞–Ω–∫.
    –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤–æ–ø—Ä–æ—Å –∏ –æ—Ç–≤–µ—Ç –≤ –æ–±—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.
    """
    context = f"–í–æ–ø—Ä–æ—Å: {question}\n–û—Ç–≤–µ—Ç: {answer}"
    return [context.strip()]


# --- –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π ---
def upload_context_from_csv(
    csv_path: str = DATA_PATH,
    collection_name: str = COLLECTION_NAME,
    qdrant_url: str = QDRANT_URL
):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç CSV —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏/–æ—Ç–≤–µ—Ç–∞–º–∏ –≤ Qdrant.
    –ö–∞–∂–¥—ã–π –≤–æ–ø—Ä–æ—Å+–æ—Ç–≤–µ—Ç -> –æ–¥–∏–Ω —á–∞–Ω–∫.
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞
    if not os.path.exists(csv_path):
        raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {csv_path}")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º CSV
    df = pd.read_csv(csv_path)
    required_cols = {"question", "answer"}
    if not required_cols.issubset(df.columns):
        raise ValueError(
            f"–í CSV –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∫–æ–ª–æ–Ω–∫–∏: {required_cols}. "
            f"–ù–∞–π–¥–µ–Ω—ã: {set(df.columns)}"
        )

    print(f"üìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π –∏–∑ {csv_path}")

    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ Qdrant
    client = QdrantClient(url=qdrant_url)
    VECTOR_SIZE = 1024

    # –ü–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º –∫–æ–ª–ª–µ–∫—Ü–∏—é
    if client.collection_exists(collection_name):
        client.delete_collection(collection_name)
        print(f"–£–¥–∞–ª–µ–Ω–∞ —Å—Ç–∞—Ä–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è '{collection_name}'")

    client.create_collection(
        collection_name=collection_name,
        vectors_config=VectorParams(size=VECTOR_SIZE, distance=Distance.COSINE)
    )
    print(f"–ö–æ–ª–ª–µ–∫—Ü–∏—è '{collection_name}' —Å–æ–∑–¥–∞–Ω–∞")

    # --- –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ---
    all_points = []
    idx_counter = 0

    for _, row in tqdm(df.iterrows(), total=len(df), desc="üîπ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø–∏—Å–µ–π"):
        question = str(row["question"])
        answer = str(row["answer"])
        category = row.get("category", "unknown")

        # –æ–¥–∏–Ω FAQ = –æ–¥–∏–Ω —á–∞–Ω–∫
        chunks = chunk_text(question, answer)

        embeddings = get_embeddings(chunks)

        for i, emb in enumerate(embeddings):
            all_points.append(
                models.PointStruct(
                    id=idx_counter,
                    vector=emb,
                    payload={
                        "question": question,
                        "answer": answer,
                        "category": category,
                        "chunk_index": i
                    }
                )
            )
            idx_counter += 1

    # --- –ó–∞–≥—Ä—É–∑–∫–∞ –≤ Qdrant ---
    client.upsert(collection_name=collection_name, points=all_points)
    print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(all_points)} –≤–µ–∫—Ç–æ—Ä–æ–≤ –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é '{collection_name}'")

    return client


if __name__ == "__main__":
    upload_context_from_csv()